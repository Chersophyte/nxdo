{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_run_results(run_dict: dict):\n",
    "    runs_to_parsed_results = {}\n",
    "    for name, json_path in run_dict.items():\n",
    "        runs_to_parsed_results[name] = {}\n",
    "        timesteps = []\n",
    "        episodes = []\n",
    "        exploitability = []\n",
    "        print(f\"parsing {json_path}\")\n",
    "        with open(json_path, \"r\") as json_file:\n",
    "            for line in json_file:\n",
    "                try:\n",
    "                    json_result = json.loads(s=line)\n",
    "                except json.JSONDecodeError:\n",
    "                    break\n",
    "\n",
    "                timesteps_entry = json_result[\"timesteps_total\"]\n",
    "                episodes_entry = json_result[\"episodes_total\"]\n",
    "                try:\n",
    "                    exploitability_entry = (json_result.get(\"avg_policy_exploitability\") or\n",
    "                                            json_result.get(\"z_avg_policy_exploitability\") or\n",
    "                                            json_result.get(\"exploitability\") or\n",
    "                                            json_result.get(\"approx_exploitability\"))\n",
    "                    if exploitability_entry is None:\n",
    "                        raise KeyError\n",
    "                    if not any(tag in json_path for tag in [\"openspiel\", \"sparse\", \"xfdo\", \"nxdo\", \"no_limit\"]):\n",
    "                        for i in range(99):\n",
    "                            try:\n",
    "                                next(json_file)\n",
    "                            except StopIteration:\n",
    "                                break\n",
    "                            except UnicodeDecodeError:\n",
    "                                continue\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "                timesteps.append(timesteps_entry)\n",
    "                episodes.append(episodes_entry)\n",
    "                exploitability.append(exploitability_entry)\n",
    "\n",
    "        runs_to_parsed_results[name][\"timesteps\"] = timesteps\n",
    "        runs_to_parsed_results[name][\"episodes\"] = episodes\n",
    "        runs_to_parsed_results[name][\"exploitability\"] = exploitability\n",
    "    return runs_to_parsed_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting /home/jb/git/grl/grl/data/m_clone_poker_data.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from grl.utils.common import data_dir\n",
    "\n",
    "# extract m_clone_poker_data.tar.gz, containing data to graph, if we haven't already done so\n",
    "if not os.path.exists(f\"{data_dir()}/20x_dummy_leduc_nfsp_dqn_gpu_sparse_08.29.31PM_Jan-27-2021zmalq5uj/result.json\"):\n",
    "    poker_data_path = f\"{data_dir()}/m_clone_poker_data.tar.gz\"\n",
    "    print(f\"extracting {poker_data_path}\")\n",
    "    tar = tarfile.open(poker_data_path, \"r:gz\")\n",
    "    tar.extractall(path=data_dir())\n",
    "    tar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add your own data here. Note that PSRO runs are parsed separately.\n",
    "nxdo_and_nfsp_runs = {\n",
    "    \"20-Clone Leduc NFSP seed 1\": f\"{data_dir()}/20x_dummy_leduc_nfsp_dqn_gpu_sparse_08.29.31PM_Jan-27-2021zmalq5uj/result.json\",\n",
    "    \"20-Clone Leduc NFSP seed 2\": f\"{data_dir()}/20x_dummy_leduc_nfsp_dqn_gpu_sparse_08.29.32PM_Jan-27-2021448z517h/result.json\",\n",
    "    \"20-Clone Leduc NFSP seed 3\": f\"{data_dir()}/20x_dummy_leduc_nfsp_dqn_gpu_sparse_08.29.34PM_Jan-27-20219a6jc3bj/result.json\",\n",
    "\n",
    "    \"20-Clone Leduc NXDO (Ours) seed 1\": f\"{data_dir()}/20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.20.33PM_Jan-27-2021/manager_results.json\",\n",
    "    \"20-Clone Leduc NXDO (Ours) seed 2\": f\"{data_dir()}/20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.02PM_Jan-27-2021/manager_results.json\",\n",
    "    \"20-Clone Leduc NXDO (Ours) seed 3\": f\"{data_dir()}/20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.06PM_Jan-27-2021/manager_results.json\",\n",
    "\n",
    "    \"20-Clone Leduc NXDO-VA (Ours) seed 1\": f\"{data_dir()}/va_20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.10PM_Jan-27-2021/manager_results.json\",\n",
    "    \"20-Clone Leduc NXDO-VA (Ours) seed 2\": f\"{data_dir()}/va_20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.12PM_Jan-27-2021/manager_results.json\",\n",
    "    \"20-Clone Leduc NXDO-VA (Ours) seed 3\": f\"{data_dir()}/va_20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.14PM_Jan-27-2021/manager_results.json\",\n",
    "\n",
    "    \"40-Clone Leduc NFSP seed 1\": f\"{data_dir()}/40x_dummy_leduc_nfsp_dqn_gpu_sparse_10.17.16PM_Jan-29-2021p9347we9/result.json\",\n",
    "    \"40-Clone Leduc NFSP seed 2\": f\"{data_dir()}/40x_dummy_leduc_nfsp_dqn_gpu_sparse_03.22.12AM_Feb-01-2021x3doc48r/result.json\",\n",
    "    \"40-Clone Leduc NFSP seed 3\": f\"{data_dir()}/40x_dummy_leduc_nfsp_dqn_gpu_sparse_03.22.21AM_Feb-01-2021a2pbfxcy/result.json\",\n",
    "\n",
    "    \"40-Clone Leduc NXDO-VA (Ours) seed 1\": f\"{data_dir()}/40x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_10.32.40PM_Jan-29-2021/manager_results.json\",\n",
    "    \"40-Clone Leduc NXDO-VA (Ours) seed 2\": f\"{data_dir()}/va_40x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_10.30.57PM_Feb-02-2021/manager_results.json\",\n",
    "    \"40-Clone Leduc NXDO-VA (Ours) seed 3\": f\"{data_dir()}/va_40x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_10.31.48PM_Feb-02-2021/manager_results.json\",\n",
    "\n",
    "    \"80-Clone Leduc NFSP seed 1\": f\"{data_dir()}/80x_dummy_leduc_nfsp_dqn_gpu_sparse_10.16.53PM_Jan-29-2021wa_a_w0w/result.json\",\n",
    "    \"80-Clone Leduc NFSP seed 2\": f\"{data_dir()}/80x_dummy_leduc_nfsp_dqn_gpu_sparse_03.10.09AM_Feb-01-2021k8g2kjub/result.json\",\n",
    "    \"80-Clone Leduc NFSP seed 3\": f\"{data_dir()}/80x_dummy_leduc_nfsp_dqn_gpu_sparse_03.10.17AM_Feb-01-2021nm0cc7zc/result.json\",\n",
    "\n",
    "    \"80-Clone Leduc NXDO-VA (Ours) seed 1\": f\"{data_dir()}/va_80x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_09.23.05PM_Jan-31-2021/manager_results.json\",\n",
    "    \"80-Clone Leduc NXDO-VA (Ours) seed 2\": f\"{data_dir()}/va_80x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_03.15.40AM_Feb-01-2021/manager_results.json\",\n",
    "    \"80-Clone Leduc NXDO-VA (Ours) seed 3\": f\"{data_dir()}/va_80x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_03.16.57AM_Feb-01-2021/manager_results.json\",\n",
    "}\n",
    "\n",
    "psro_runs = {\n",
    "    \"20-Clone Leduc DQN-PSRO seed 1\": f\"{data_dir()}/seed_0_20x_dummy_leduc_psro_dqn_gpu_08.29.17PM_Jan-27-2021.json\",\n",
    "    \"20-Clone Leduc DQN-PSRO seed 2\": f\"{data_dir()}/seed_1_20x_dummy_leduc_psro_dqn_gpu_08.29.19PM_Jan-27-2021.json\",\n",
    "    \"20-Clone Leduc DQN-PSRO seed 3\": f\"{data_dir()}/seed_2_20x_dummy_leduc_psro_dqn_gpu_08.29.25PM_Jan-27-2021.json\",\n",
    "\n",
    "    \"40-Clone Leduc DQN-PSRO seed 1\": f\"{data_dir()}/40x_dummy_leduc_psro_dqn_gpu_03.33.30AM_Feb-01-2021.json\",\n",
    "    \"40-Clone Leduc DQN-PSRO seed 2\": f\"{data_dir()}/40x_dummy_leduc_psro_dqn_gpu_04.59.02AM_Feb-03-2021.json\",\n",
    "    \"40-Clone Leduc DQN-PSRO seed 3\": f\"{data_dir()}/40x_dummy_leduc_psro_dqn_gpu_02.41.27AM_Feb-04-2021.json\",\n",
    "\n",
    "    \"80-Clone Leduc DQN-PSRO seed 1\": f\"{data_dir()}/80x_dummy_leduc_psro_dqn_gpu_03.13.11AM_Feb-01-2021.json\",\n",
    "    \"80-Clone Leduc DQN-PSRO seed 2\": f\"{data_dir()}/80x_dummy_leduc_psro_dqn_gpu_03.11.23AM_Feb-01-2021.json\",\n",
    "    \"80-Clone Leduc DQN-PSRO seed 3\": f\"{data_dir()}/80x_dummy_leduc_psro_dqn_gpu_09.24.25PM_Jan-31-2021.json\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing /home/jb/git/grl/grl/data/20x_dummy_leduc_nfsp_dqn_gpu_sparse_08.29.31PM_Jan-27-2021zmalq5uj/result.json\n",
      "parsing /home/jb/git/grl/grl/data/20x_dummy_leduc_nfsp_dqn_gpu_sparse_08.29.32PM_Jan-27-2021448z517h/result.json\n",
      "parsing /home/jb/git/grl/grl/data/20x_dummy_leduc_nfsp_dqn_gpu_sparse_08.29.34PM_Jan-27-20219a6jc3bj/result.json\n",
      "parsing /home/jb/git/grl/grl/data/20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.20.33PM_Jan-27-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.02PM_Jan-27-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.06PM_Jan-27-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/va_20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.10PM_Jan-27-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/va_20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.12PM_Jan-27-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/va_20x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_08.29.14PM_Jan-27-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/40x_dummy_leduc_nfsp_dqn_gpu_sparse_10.17.16PM_Jan-29-2021p9347we9/result.json\n",
      "parsing /home/jb/git/grl/grl/data/40x_dummy_leduc_nfsp_dqn_gpu_sparse_03.22.12AM_Feb-01-2021x3doc48r/result.json\n",
      "parsing /home/jb/git/grl/grl/data/40x_dummy_leduc_nfsp_dqn_gpu_sparse_03.22.21AM_Feb-01-2021a2pbfxcy/result.json\n",
      "parsing /home/jb/git/grl/grl/data/40x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_10.32.40PM_Jan-29-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/va_40x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_10.30.57PM_Feb-02-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/va_40x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_10.31.48PM_Feb-02-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/80x_dummy_leduc_nfsp_dqn_gpu_sparse_10.16.53PM_Jan-29-2021wa_a_w0w/result.json\n",
      "parsing /home/jb/git/grl/grl/data/80x_dummy_leduc_nfsp_dqn_gpu_sparse_03.10.09AM_Feb-01-2021k8g2kjub/result.json\n",
      "parsing /home/jb/git/grl/grl/data/80x_dummy_leduc_nfsp_dqn_gpu_sparse_03.10.17AM_Feb-01-2021nm0cc7zc/result.json\n",
      "parsing /home/jb/git/grl/grl/data/va_80x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_09.23.05PM_Jan-31-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/va_80x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_03.15.40AM_Feb-01-2021/manager_results.json\n",
      "parsing /home/jb/git/grl/grl/data/va_80x_dummy_leduc_xfdo_dqn_nfsp_gpu_dynamic_threshold_1_aggressive/manager_03.16.57AM_Feb-01-2021/manager_results.json\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from grl.utils.common import datetime_str\n",
    "# pio.renderers.default = 'png'\n",
    "pio.renderers.default = \"browser\"\n",
    "\n",
    "\n",
    "runs_to_parsed_results = parse_run_results(run_dict=nxdo_and_nfsp_runs)\n",
    "\n",
    "timesteps = list(itertools.chain(*[v[\"timesteps\"] for k, v in runs_to_parsed_results.items()]))\n",
    "episodes = list(itertools.chain(*[v[\"episodes\"] for k, v in runs_to_parsed_results.items()]))\n",
    "\n",
    "exploitability = list(itertools.chain(*[v[\"exploitability\"] for k, v in runs_to_parsed_results.items()]))\n",
    "run = list(itertools.chain(*[[k] * len(v[\"exploitability\"]) for k, v in runs_to_parsed_results.items()]))\n",
    "\n",
    "in_dict = {\n",
    "    \"timesteps\": timesteps,\n",
    "    \"episodes\": episodes,\n",
    "    \"exploitability\": exploitability,\n",
    "    \"run\": run,\n",
    "}\n",
    "\n",
    "for run_name, data_path in psro_runs.items():\n",
    "    with open(data_path, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    filtered_data = {}\n",
    "    for key, column in data.items():\n",
    "        filtered_data[key] = []\n",
    "        for i, item in enumerate(column):\n",
    "            if data[\"exploitability\"][i] is not None:\n",
    "                filtered_data[key].append(data[key][i])\n",
    "    data = filtered_data\n",
    "\n",
    "    timesteps = data.get(\"timesteps\") or data.get(\"timesteps_total\") or data[\"total_steps\"]\n",
    "    episodes = data.get(\"episodes\") or data.get(\"episodes_total\") or data[\"total_episodes\"]\n",
    "\n",
    "    assert len(timesteps) == len(episodes)\n",
    "    assert len(data[\"exploitability\"]) == len(timesteps)\n",
    "\n",
    "    in_dict[\"timesteps\"].extend(timesteps)\n",
    "    in_dict[\"episodes\"].extend(episodes)\n",
    "    in_dict[\"exploitability\"].extend(data[\"exploitability\"])\n",
    "    in_dict[\"run\"].extend(run_name for _ in data[\"exploitability\"])\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(data=in_dict)\n",
    "fig = px.line(df, x=\"episodes\", y=\"exploitability\", color=\"run\", title='Poker Exploitability')\n",
    "\n",
    "# toggles runs to be invisible by default\n",
    "fig.for_each_trace(lambda trace: trace.update(visible=\"legendonly\"))\n",
    "\n",
    "fig.add_annotation(\n",
    "                text=\"Double-click the legend to toggle visibility of all runs.\",\n",
    "                align='left',\n",
    "                showarrow=False,\n",
    "                xref='paper',\n",
    "                yref='paper',\n",
    "                xanchor=\"left\",\n",
    "                x=1,\n",
    "                y=0.0,\n",
    "                bordercolor=None,\n",
    "                borderwidth=1\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(f\"/tmp/exploitability_{datetime_str()}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}