{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jb/anaconda3/envs/grl/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from grl.p2sro.p2sro_manager import P2SROManager\n",
    "from grl.p2sro.payoff_table import PayoffTable\n",
    "from grl.p2sro.p2sro_manager.utils import get_latest_metanash_strategies, PolicySpecDistribution\n",
    "from grl.rl_examples.particle_games.simple_push_multi_agent_env import SimplePushMultiAgentEnv\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Type\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import deepdish\n",
    "import ray\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "\n",
    "from ray.rllib.utils import merge_dicts\n",
    "from ray.rllib.policy.policy import Policy\n",
    "from ray.rllib.agents.sac import SACTorchPolicy, DEFAULT_CONFIG as DEFAULT_SAC_CONFIG\n",
    "from grl.p2sro.eval_dispatcher.remote import RemoteEvalDispatcherClient\n",
    "from grl.rl_examples.particle_games.config import simple_push_sac_params_small\n",
    "from grl.p2sro.payoff_table import PayoffTableStrategySpec\n",
    "\n",
    "\n",
    "def arcus_path_to_goku_path(path: str):\n",
    "    return path.replace(\"/jblanier/\", \"/jb/\")\n",
    "\n",
    "def load_weights(policy: Policy, pure_strat_spec: PayoffTableStrategySpec = None, checkpoint_path=None):\n",
    "    assert pure_strat_spec is None or checkpoint_path is None\n",
    "    if pure_strat_spec:\n",
    "        pure_strat_checkpoint_path = pure_strat_spec.metadata[\"checkpoint_path\"]\n",
    "    else:\n",
    "        pure_strat_checkpoint_path = checkpoint_path\n",
    "\n",
    "    pure_strat_checkpoint_path = arcus_path_to_goku_path(pure_strat_checkpoint_path)\n",
    "\n",
    "    checkpoint_data = deepdish.io.load(path=pure_strat_checkpoint_path)\n",
    "    weights = checkpoint_data[\"weights\"]\n",
    "    weights = {k.replace(\"_dot_\", \".\"): v for k, v in weights.items()}\n",
    "    policy.set_weights(weights=weights)\n",
    "\n",
    "\n",
    "\n",
    "def run_episode(env, policies_for_each_player, render=False) -> np.ndarray:\n",
    "\n",
    "    num_players = len(policies_for_each_player)\n",
    "\n",
    "    obs = env.reset()\n",
    "    dones = {}\n",
    "    game_length = 0\n",
    "    policy_states = [None] * num_players\n",
    "\n",
    "    payoffs_per_player_this_episode = np.zeros(shape=num_players, dtype=np.float64)\n",
    "    while True:\n",
    "        if \"__all__\" in dones:\n",
    "            if dones[\"__all__\"]:\n",
    "                break\n",
    "        game_length += 1\n",
    "        time.sleep(0.1)\n",
    "        action_dict = {}\n",
    "        for player in range(num_players):\n",
    "            if player in obs:\n",
    "                action_index, new_policy_state, action_info = policies_for_each_player[player].compute_single_action(\n",
    "                    obs=obs[player], state=policy_states[player])\n",
    "                policy_states[player] = new_policy_state\n",
    "                action_dict[player] = action_index\n",
    "\n",
    "        obs, rewards, dones, infos = env.step(action_dict=action_dict)\n",
    "        if render:\n",
    "            env.render()\n",
    "\n",
    "        for player in range(num_players):\n",
    "            payoff_so_far = payoffs_per_player_this_episode[player]\n",
    "            payoffs_per_player_this_episode[player] = payoff_so_far + rewards.get(player, 0.0)\n",
    "\n",
    "    return payoffs_per_player_this_episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payoff matrix as 1 (row) against 0 (columns):\n",
      "[[ 0.         -0.02401407 -0.04443765 ...  1.28148699  0.58778667\n",
      "   0.51695776]\n",
      " [ 0.02401407  0.          1.28426635 ...  2.04232836  1.05170274\n",
      "   0.66932929]\n",
      " [ 0.04443765 -1.28426635  0.         ...  2.47086668  2.96118617\n",
      "   1.81787074]\n",
      " ...\n",
      " [-1.28148699 -2.04232836 -2.47086668 ...  0.          0.46119061\n",
      "  -0.50427115]\n",
      " [-0.58778667 -1.05170274 -2.96118617 ... -0.46119061  0.\n",
      "  -0.72462857]\n",
      " [-0.51695776 -0.66932929 -1.81787074 ...  0.50427115  0.72462857\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "simple_push_large_params_psro_payoff_table_checkpoint_path = \"/home/jb/git/grl/grl/data/manager_12.45.57AM_Dec-21-2020/payoff_table_checkpoints/payoff_table_checkpoint_70.json\"\n",
    "simple_push_large_params_psro_payoff_table = PayoffTable.from_json_file(\n",
    "    json_file_path=simple_push_large_params_psro_payoff_table_checkpoint_path)\n",
    "\n",
    "\n",
    "psro_strats = get_latest_metanash_strategies(payoff_table=simple_push_large_params_psro_payoff_table,\n",
    "                                             as_player=0,\n",
    "                                             as_policy_num=70,\n",
    "                                             fictitious_play_iters=2000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "probabilities_for_each_strategy = psro_strats[1].probabilities_for_each_strategy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(71, 71)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_push_large_params_psro_payoff_table.shape()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-29 10:13:35,597\tWARNING sac_tf_policy.py:63 -- When not using a state-preprocessor with SAC, `fcnet_hiddens` will be set to an empty list! Any hidden layer sizes are defined via `policy_model.fcnet_hiddens` and `Q_model.fcnet_hiddens`.\n",
      "2020-12-29 10:13:36,758\tWARNING sac_tf_policy.py:63 -- When not using a state-preprocessor with SAC, `fcnet_hiddens` will be set to an empty list! Any hidden layer sizes are defined via `policy_model.fcnet_hiddens` and `Q_model.fcnet_hiddens`.\n"
     ]
    }
   ],
   "source": [
    "env = SimplePushMultiAgentEnv(env_config={})\n",
    "\n",
    "policy_class = SACTorchPolicy\n",
    "policies = [policy_class(env.observation_space,\n",
    "                         env.action_space,\n",
    "                         merge_dicts(DEFAULT_SAC_CONFIG, simple_push_sac_params_small(action_space=env.action_space)))\n",
    "            for _ in range(2)]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.10058123 -4.10058123]\n",
      "[-73.19352985  73.19352985]\n",
      "[ 3.61957171 -3.61957171]\n",
      "[ 9.39552767 -9.39552767]\n",
      "[ 8.61421926 -8.61421926]\n",
      "[-33.91738001  33.91738001]\n",
      "[ 10.61900742 -10.61900742]\n",
      "[ 5.69334235 -5.69334235]\n",
      "[ 5.9652022 -5.9652022]\n",
      "[-56.59009153  56.59009153]\n",
      "[ 4.50155334 -4.50155334]\n",
      "[ 0.11645411 -0.11645411]\n",
      "[-23.64318313  23.64318313]\n",
      "[ 4.83279944 -4.83279944]\n",
      "[-25.34578466  25.34578466]\n",
      "[-148.36690618  148.36690618]\n",
      "[-91.88343715  91.88343715]\n",
      "[-33.14098525  33.14098525]\n",
      "[ 5.7619823 -5.7619823]\n",
      "[-93.01432321  93.01432321]\n",
      "[-12.6078147  12.6078147]\n",
      "[ 3.2221016 -3.2221016]\n",
      "[ 1.23025996 -1.23025996]\n",
      "[ 4.37209543 -4.37209543]\n",
      "[ 12.98634674 -12.98634674]\n",
      "[-98.60562249  98.60562249]\n",
      "[-80.33828414  80.33828414]\n",
      "[-11.55596129  11.55596129]\n",
      "[ 6.11246916 -6.11246916]\n",
      "[-40.12408555  40.12408555]\n",
      "[-103.95790819  103.95790819]\n",
      "[ 7.43730874 -7.43730874]\n",
      "[ 7.16083778 -7.16083778]\n",
      "[-38.41514604  38.41514604]\n",
      "[-21.25103596  21.25103596]\n",
      "[-55.81686949  55.81686949]\n",
      "[ 2.32663623 -2.32663623]\n",
      "[ 3.8256392 -3.8256392]\n",
      "[-79.40866927  79.40866927]\n",
      "[ 18.21565191 -18.21565191]\n",
      "[ 4.16087954 -4.16087954]\n",
      "[-16.8365757  16.8365757]\n",
      "[ 9.02022548 -9.02022548]\n",
      "[-45.57519952  45.57519952]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-5941233d776a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mpayoffs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun_episode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpolicies_for_each_player\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpolicies\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrender\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpayoffs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-1-f5981c03c624>\u001B[0m in \u001B[0;36mrun_episode\u001B[0;34m(env, policies_for_each_player, render)\u001B[0m\n\u001B[1;32m     56\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m         \u001B[0mgame_length\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 58\u001B[0;31m         \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     59\u001B[0m         \u001B[0maction_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mplayer\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_players\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    # load_weights(policy=policies[0], checkpoint_path=\"/home/jb/Downloads/best_response_0_1_12.03.04AM_Dec-27-2020.h5\")\n",
    "    # load_weights(policy=policies[1], checkpoint_path=\"/home/jb/Downloads/best_response_1_1_12.03.04AM_Dec-27-2020.h5\")\n",
    "\n",
    "    load_weights(policy=policies[0], checkpoint_path=\"/home/jb/Downloads/best_response_0_71_10.15.13PM_Dec-27-2020.h5\")\n",
    "    load_weights(policy=policies[1], checkpoint_path=\"/home/jb/Downloads/best_response_1_71_10.15.13PM_Dec-27-2020.h5\")\n",
    "\n",
    "\n",
    "    payoffs = run_episode(env=env, policies_for_each_player=policies, render=True)\n",
    "    print(payoffs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}